{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97913e07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T01:06:45.807917Z",
     "start_time": "2023-03-14T01:06:45.797916Z"
    }
   },
   "outputs": [],
   "source": [
    "import json  #to be needed to read and load the message.json files that FB provides - https://docs.python.org/3/library/json.html\n",
    "import os    #import os library to access folders in windows - https://docs.python.org/3/library/os.html\n",
    "import ftfy  #library to fix the Greek characters mojibake error\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c13dcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T01:06:46.350408Z",
     "start_time": "2023-03-14T01:06:46.339404Z"
    }
   },
   "outputs": [],
   "source": [
    "#define a fix_text internal function\n",
    "def mojibake(string):\n",
    "    #return string  #just to kill the function and do nothing\n",
    "    return ftfy.fix_text(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mojibake('ΟΞµ Ο€Ξ±ΞΉΞ΄ΞΉΞ¬ ΞµΞ³Ο Ξ¬Ξ»Ξ»ΞΏΟ… Ξ­ΟƒΟ„ΞµΞΉΞ»Ξ± Ο„ΞΏΟ…Ο‚ ΞµΞ―Ο€Ξ± π¤£')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52afc3a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T01:06:47.695983Z",
     "start_time": "2023-03-14T01:06:47.676983Z"
    }
   },
   "outputs": [],
   "source": [
    "# download your Messenger data from Facebook\n",
    "# set the path to the folder \n",
    "\n",
    "path_to_source_folder = 'D:/Kalimera/2023/downloaded_on_08.Jun.2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1450e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T01:06:50.085725Z",
     "start_time": "2023-03-14T01:06:50.076724Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create the Headers for the all 3 Dataset files\n",
    "\n",
    "headers_conversation_ds = [\n",
    "    'Key_C',\n",
    "    'Participants',\n",
    "    'Title',\n",
    "    'Is_still_participant',\n",
    "    'no_of_participants'\n",
    "]\n",
    "\n",
    "headers_messages_ds = [\n",
    "    'Key_M',\n",
    "    'Conversation',\n",
    "    'Sender_name',\n",
    "    'Timestamp_ms',\n",
    "    'Message_text',\n",
    "    'Message_type',\n",
    "    'Call_duration',\n",
    "    'Web_link',\n",
    "    'Is_unsent'\n",
    "]\n",
    "\n",
    "headers_reactions_ds = [\n",
    "    'Key_R',\n",
    "    'Message',\n",
    "    'Reaction',\n",
    "    'Actor'    \n",
    "]\n",
    "\n",
    "headers_dict = {\n",
    "    'conversations' : headers_conversation_ds,\n",
    "    'messages' :headers_messages_ds,\n",
    "    'reactions' : headers_reactions_ds\n",
    "}\n",
    "\n",
    "headers_csv_dict = {}\n",
    "\n",
    "for key, hl in headers_dict.items():\n",
    "    header_string = ''\n",
    "    header_string += hl[0]\n",
    "    for i in range(1,len(hl)):\n",
    "        header_string += ';'\n",
    "        header_string += hl[i]\n",
    "    header_string += '\\n'    \n",
    "    headers_csv_dict[key] = header_string\n",
    "\n",
    "#headers_csv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a3e7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T01:07:55.213837Z",
     "start_time": "2023-03-14T01:06:52.372111Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a string for each entry (row) or the 3 datasets - csv files\n",
    "\n",
    "#initialize the 3 dataset lists\n",
    "conversation_list = []\n",
    "messages_list = []\n",
    "reactions_list = []\n",
    "\n",
    "#initialize the 3 keys\n",
    "key_c = 1\n",
    "key_m = 1\n",
    "key_r = 1\n",
    "\n",
    "for root, dirs, files in os.walk(path_to_source_folder):\n",
    "    for file in files:\n",
    "        if file[:7] == 'message':\n",
    "            path = root+'/'+file\n",
    "            with open(path, encoding = 'utf8') as file:\n",
    "                conversation_dict = json.load(file)\n",
    "                \n",
    "                # create the messages dataset row \n",
    "                #iterate through the internal messages list\n",
    "                for message in conversation_dict['messages']:\n",
    "                    message_sender_name = mojibake(message['sender_name'])\n",
    "                    message_timestamp = message['timestamp_ms']\n",
    "                    message_text = ''\n",
    "                    if 'content' in message.keys(): message_text = mojibake(message['content']).replace(';','?').replace('\\n', ' -new line- ')\n",
    "                    \n",
    "                    message_type = ''\n",
    "#                     if \n",
    "#                     elif\n",
    "#                     elif\n",
    "                                        \n",
    "                    message_call_duration = ''\n",
    "                    if 'call_duration' in message.keys(): message_call_duration = message['call_duration']\n",
    "                    message_link = ''\n",
    "                    if 'share' in message.keys():\n",
    "                        if 'link' in message['share'].keys():\n",
    "                            message_link = message['share']['link'].replace(';','?')\n",
    "                    message_is_unsent = False\n",
    "                    if 'is_unsent' in message.keys(): message_is_unsent = message['is_unsent']  \n",
    "                    \n",
    "                    temp_m = f'{key_m};{key_c};{message_sender_name};{message_timestamp};{message_text};{message_type};{message_call_duration};{message_link};{message_is_unsent}\\n'\n",
    "                    messages_list.append(temp_m)\n",
    "                    \n",
    "                    # create the reactions dataset row     \n",
    "                    if 'reactions' in message.keys():\n",
    "                        for reaction in message['reactions']:\n",
    "                            reaction_reaction = mojibake(reaction['reaction'])\n",
    "                            reaction_actor = mojibake(reaction['actor'])\n",
    "                            \n",
    "                            temp_r = f'{key_r};{key_m};{reaction_reaction};{reaction_actor}\\n'\n",
    "                            reactions_list.append(temp_r)\n",
    "                            \n",
    "                            # increase the reaction counter key\n",
    "                            key_r += 1  \n",
    "                    \n",
    "                    # increase the messages counter key\n",
    "                    key_m += 1\n",
    "                    \n",
    "    \n",
    "            # create the conversation dataset row \n",
    "            # if many \"message_x.json\" files exist, the entry will be executed only for the last one\n",
    "            # all files are part of the same conversation and store the same data\n",
    "            conversation_title = mojibake(conversation_dict['title'])\n",
    "            conversation_no_of_participants = len(conversation_dict['participants'])\n",
    "            conversation_is_still_participant = conversation_dict['is_still_participant']\n",
    "            conversation_name_of_participants = ''\n",
    "            for name in conversation_dict['participants']:\n",
    "                conversation_name_of_participants += mojibake(name['name'])\n",
    "                conversation_name_of_participants += ','\n",
    "            conversation_name_of_participants = conversation_name_of_participants[:-1] #cut the last semicolon \n",
    "            temp_c = f'{key_c};{conversation_name_of_participants};{conversation_title};{conversation_is_still_participant};{conversation_no_of_participants}\\n'\n",
    "            conversation_list.append(temp_c)                    \n",
    "            # increase the conversation counter key\n",
    "            key_c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(conversation_list))\n",
    "# conversation_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(messages_list))\n",
    "# messages_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(reactions_list))\n",
    "# reactions_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58552a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T01:08:02.373059Z",
     "start_time": "2023-03-14T01:08:00.748364Z"
    }
   },
   "outputs": [],
   "source": [
    "#create the output csv files\n",
    "data_dict = {\n",
    "    'conversations' : conversation_list,\n",
    "    'messages' : messages_list,\n",
    "    'reactions' : reactions_list\n",
    "}\n",
    "\n",
    "date_time = dt.now().strftime(\"%Y.%m.%d_%H.%M\")  # '2023.08.16_15.39'\n",
    "\n",
    "for name, value in headers_csv_dict.items():\n",
    "    # headers\n",
    "    file_name = name+'_'+date_time+'.csv'\n",
    "    with open(file_name, 'w', encoding='UTF8') as output:\n",
    "        output.write(value)\n",
    "    # rows \n",
    "    #iterate through the list and add all entries to the file    \n",
    "    with open(file_name, 'a', encoding='UTF8') as output:\n",
    "        for i in data_dict[name]:\n",
    "            output.write(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
